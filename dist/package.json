{
  "name": "gs-tokenizer",
  "version": "0.1.10",
  "type": "module",
  "main": "lib/index.cjs",
  "module": "lib/index.js",
  "exports": {
    ".": {
      "import": "./lib/index.js",
      "require": "./lib/index.cjs",
      "types": "./lib/index.d.ts"
    },
    "./core": {
      "import": "./lib/core.js",
      "require": "./lib/core.cjs",
      "types": "./lib/core.d.ts"
    },
    "./lexicon": {
		"import": "./lib/lexicon.js",
		"require": "./lib/lexicon.cjs",
		"types": "./lib/lexicon.d.ts"
	}
  },
  "types": "lib/index.d.ts",
  "keywords": [
    "tokenizer",
    "multilingual",
    "nlp",
    "natural-language-processing",
    "english",
    "chinese",
    "japanese",
    "korean",
    "cjk"
  ],
  "homepage": "https://github.com/grain-sand/gs-tokenizer",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/grain-sand/gs-tokenizer.git"
  },
  "bugs": {
    "url": "https://github.com/grain-sand/gs-tokenizer/issues"
  },
  "author": "grain-sand",
  "license": "MIT",
  "dependencies": {}
}
