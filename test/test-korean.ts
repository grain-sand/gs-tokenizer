import {beforeEach, describe, expect, it} from "vitest";
import { MultilingualTokenizer } from "../src/core";

// // const console = (top as any).console;

describe('Multilingual Tokenizer - Korean Tests', () => {
  let tokenizer: MultilingualTokenizer;

  beforeEach(() => {
    tokenizer = new MultilingualTokenizer();
  });

  it('should tokenize Korean text by natural words', () => {
    const text = 'ì•ˆë…•í•˜ì„¸ìš?ì„¸ê³„! ì €ëŠ?í•œêµ­ì¸ìž…ë‹ˆë‹¤.';
    console.log('Testing Korean tokenization:', text);
    
    const tokens = tokenizer.tokenize(text);
    const wordTokens = tokens.filter(token => token.type === 'word').map(token => token.txt);
    
    console.log('Korean tokenization result:', wordTokens);
    console.log('Full tokens:', tokens);
    
    expect(wordTokens.length).toBeGreaterThan(0);
    expect(tokens.some(token => token.lang === 'ko')).toBe(true);
  });

  it('should handle Korean sentences correctly', () => {
    const text = 'í•œêµ­ì–´ëŠ” ì•„ë¦„ë‹¤ìš´ ì–¸ì–´ìž…ë‹ˆë‹?';
    console.log('Testing Korean sentence:', text);
    
    const tokens = tokenizer.tokenize(text);
    const wordTokens = tokens.filter(token => token.type === 'word').map(token => token.txt);
    
    console.log('Korean sentence result:', wordTokens);
    
    expect(wordTokens.length).toBeGreaterThan(0);
    expect(tokens.some(token => token.lang === 'ko')).toBe(true);
  });
});
